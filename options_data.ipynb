{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86bc8b4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# app/main.py\n",
    "import os\n",
    "import time\n",
    "import json\n",
    "import bisect\n",
    "import tempfile\n",
    "from datetime import datetime\n",
    "from typing import List, Optional, Dict, Any\n",
    "\n",
    "import pandas as pd\n",
    "from fastapi import FastAPI, HTTPException, BackgroundTasks, Query\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# External provider functions from nsepython\n",
    "# make sure you have `nsepython` installed in your env:\n",
    "# pip install nsepython\n",
    "from nsepython import option_chain, nse_quote\n",
    "\n",
    "# ---------------------------\n",
    "# Models\n",
    "# ---------------------------\n",
    "\n",
    "class IndexPriceResponse(BaseModel):\n",
    "    symbol: str\n",
    "    lastPrice: float\n",
    "    pChange: float\n",
    "    change: float\n",
    "    timestamp: str\n",
    "\n",
    "class StockPriceResponse(BaseModel):\n",
    "    symbol: str\n",
    "    companyName: Optional[str] = None\n",
    "    lastPrice: Optional[float] = None\n",
    "    pChange: Optional[float] = None\n",
    "    change: Optional[float] = None\n",
    "    timestamp: str\n",
    "\n",
    "class FetchOptionsRequest(BaseModel):\n",
    "    index: str = Field(..., description=\"Index symbol, e.g. NIFTY or BANKNIFTY\")\n",
    "    num_strikes: int = Field(25, gt=0, le=500)\n",
    "\n",
    "class FetchExpiryRequest(BaseModel):\n",
    "    index: str\n",
    "    expiry: str\n",
    "    num_strikes: int = Field(25, gt=0, le=500)\n",
    "\n",
    "class FetchResultMeta(BaseModel):\n",
    "    createdAtUTC: str\n",
    "    indexName: str\n",
    "    nearestExpiry: Optional[str] = None\n",
    "    selectedExpiry: Optional[str] = None\n",
    "    underlyingValue: Optional[float] = None\n",
    "    atmStrike: Optional[int] = None\n",
    "    selectedStrikesRange: Optional[List[int]] = None\n",
    "    totalStrikesFetched: Optional[int] = None\n",
    "\n",
    "class AnalyticsResponse(BaseModel):\n",
    "    meta: FetchResultMeta\n",
    "    pcr: Dict[str, float]\n",
    "    top_oi: Dict[str, List[Dict[str, Any]]]\n",
    "    max_pain: Dict[str, Any]\n",
    "\n",
    "# ---------------------------\n",
    "# App & config\n",
    "# ---------------------------\n",
    "\n",
    "app = FastAPI(title=\"Option Chain API\", version=\"1.0\",\n",
    "              description=\"Fetch option chains from NSE and return analytics (PCR / MaxPain / Top OI).\")\n",
    "\n",
    "OUTPUT_DIR = os.environ.get(\"OPTION_OUTPUT_DIR\", \"option_chain_data\")\n",
    "os.makedirs(OUTPUT_DIR, exist_ok=True)\n",
    "\n",
    "# ---------------------------\n",
    "# Helpers (adapted from your script)\n",
    "# ---------------------------\n",
    "\n",
    "def _expand_side(df: pd.DataFrame, side: str) -> pd.DataFrame:\n",
    "    valid_rows = df[df[side].apply(lambda x: isinstance(x, dict))]\n",
    "    if valid_rows.empty:\n",
    "        return pd.DataFrame()\n",
    "    side_data = valid_rows[side].apply(pd.Series)\n",
    "    side_data = side_data.add_prefix(f'{side}_')\n",
    "    return side_data\n",
    "\n",
    "def _atomic_write_csv(df: pd.DataFrame, target_path: str):\n",
    "    # write to temp file then atomically replace\n",
    "    dirpath = os.path.dirname(target_path)\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", dir=dirpath, delete=False, suffix=\".csv\") as tmp:\n",
    "        tmp_name = tmp.name\n",
    "        df.to_csv(tmp_name, index=False)\n",
    "    os.replace(tmp_name, target_path)\n",
    "\n",
    "def _atomic_write_json(obj: dict, target_path: str):\n",
    "    dirpath = os.path.dirname(target_path)\n",
    "    os.makedirs(dirpath, exist_ok=True)\n",
    "    with tempfile.NamedTemporaryFile(mode=\"w\", dir=dirpath, delete=False, suffix=\".json\", encoding=\"utf-8\") as tmp:\n",
    "        tmp_name = tmp.name\n",
    "        json.dump(obj, tmp, indent=2)\n",
    "    os.replace(tmp_name, target_path)\n",
    "\n",
    "def _normalize_index_name(index: str) -> str:\n",
    "    if not index:\n",
    "        return \"\"\n",
    "    s = index.strip().upper()\n",
    "    if s in (\"NIFTY50\", \"NIFTY\", \"NSEI\"):\n",
    "        return \"NIFTY\"\n",
    "    if s in (\"BANKNIFTY\", \"NSEBANK\"):\n",
    "        return \"BANKNIFTY\"\n",
    "    return s\n",
    "\n",
    "# ---------------------------\n",
    "# Analytical helpers (your logic)\n",
    "# ---------------------------\n",
    "\n",
    "def calculate_pcr(df: pd.DataFrame) -> dict:\n",
    "    pcr_data = {'pcr_by_oi': 0.0, 'pcr_by_volume': 0.0}\n",
    "    if 'PE_openInterest' in df.columns and 'CE_openInterest' in df.columns:\n",
    "        total_pe_oi = df['PE_openInterest'].fillna(0).sum()\n",
    "        total_ce_oi = df['CE_openInterest'].fillna(0).sum()\n",
    "        if total_ce_oi > 0:\n",
    "            pcr_data['pcr_by_oi'] = round(total_pe_oi / total_ce_oi, 2)\n",
    "    if 'PE_totalTradedVolume' in df.columns and 'CE_totalTradedVolume' in df.columns:\n",
    "        total_pe_volume = df['PE_totalTradedVolume'].fillna(0).sum()\n",
    "        total_ce_volume = df['CE_totalTradedVolume'].fillna(0).sum()\n",
    "        if total_ce_volume > 0:\n",
    "            pcr_data['pcr_by_volume'] = round(total_pe_volume / total_ce_volume, 2)\n",
    "    return pcr_data\n",
    "\n",
    "def find_high_oi_strikes(df: pd.DataFrame, top_n: int = 5) -> dict:\n",
    "    results = {'resistance_strikes': [], 'support_strikes': []}\n",
    "    if 'CE_openInterest' in df.columns:\n",
    "        top_calls = df.nlargest(top_n, 'CE_openInterest')[['strikePrice', 'CE_openInterest']].fillna(0)\n",
    "        results['resistance_strikes'] = top_calls.to_dict('records')\n",
    "    if 'PE_openInterest' in df.columns:\n",
    "        top_puts = df.nlargest(top_n, 'PE_openInterest')[['strikePrice', 'PE_openInterest']].fillna(0)\n",
    "        results['support_strikes'] = top_puts.to_dict('records')\n",
    "    return results\n",
    "\n",
    "def calculate_max_pain(df: pd.DataFrame) -> dict:\n",
    "    if 'strikePrice' not in df.columns:\n",
    "        return {'max_pain_strike': None, 'max_loss_value': 0}\n",
    "    strikes = sorted(df['strikePrice'].dropna().unique())\n",
    "    total_loss_at_strike = {}\n",
    "    for strike_price in strikes:\n",
    "        loss = 0\n",
    "        if 'CE_openInterest' in df.columns and 'CE_lastPrice' in df.columns:\n",
    "            ce_data = df[['strikePrice', 'CE_openInterest', 'CE_lastPrice']].dropna()\n",
    "            for _, row in ce_data.iterrows():\n",
    "                if row['strikePrice'] > strike_price:\n",
    "                    loss += (row['strikePrice'] - strike_price) * row['CE_openInterest']\n",
    "        if 'PE_openInterest' in df.columns and 'PE_lastPrice' in df.columns:\n",
    "            pe_data = df[['strikePrice', 'PE_openInterest', 'PE_lastPrice']].dropna()\n",
    "            for _, row in pe_data.iterrows():\n",
    "                if row['strikePrice'] < strike_price:\n",
    "                    loss += (strike_price - row['strikePrice']) * row['PE_openInterest']\n",
    "        total_loss_at_strike[strike_price] = loss\n",
    "    if not total_loss_at_strike:\n",
    "        return {'max_pain_strike': None, 'max_loss_value': 0}\n",
    "    max_pain_strike = min(total_loss_at_strike, key=total_loss_at_strike.get)\n",
    "    return {'max_pain_strike': int(max_pain_strike), 'max_loss_value': int(total_loss_at_strike[max_pain_strike])}\n",
    "\n",
    "# ---------------------------\n",
    "# Core fetch + save (refactored)\n",
    "# ---------------------------\n",
    "\n",
    "def _prepare_option_chain_df(resp: dict, expiry: str) -> pd.DataFrame:\n",
    "    if not (isinstance(resp, dict) and 'records' in resp and 'data' in resp['records']):\n",
    "        raise RuntimeError(\"Invalid response structure from NSE.\")\n",
    "    df_full = pd.DataFrame(resp['records']['data'])\n",
    "    if df_full.empty:\n",
    "        raise RuntimeError(\"No option chain data returned by NSE.\")\n",
    "    if 'strikePrice' not in df_full.columns:\n",
    "        raise RuntimeError(\"Column 'strikePrice' missing from NSE response.\")\n",
    "    df_full['strikePrice'] = pd.to_numeric(df_full['strikePrice'], errors='coerce')\n",
    "    df = df_full[df_full['expiryDate'] == expiry].copy()\n",
    "    if df.empty:\n",
    "        raise RuntimeError(f\"No data for expiry {expiry}\")\n",
    "    ce_data = _expand_side(df, 'CE')\n",
    "    pe_data = _expand_side(df, 'PE')\n",
    "    df_processed = pd.concat([df[['strikePrice', 'expiryDate']].reset_index(drop=True), ce_data.reset_index(drop=True), pe_data.reset_index(drop=True)], axis=1)\n",
    "    return df_processed\n",
    "\n",
    "def _select_strikes_and_save(df_processed: pd.DataFrame, resp: dict, index_name: str, expiry: str, num_strikes: int) -> FetchResultMeta:\n",
    "    underlying_value = float(resp['records'].get('underlyingValue', 0))\n",
    "    strikes = sorted(df_processed['strikePrice'].dropna().unique())\n",
    "    if not strikes:\n",
    "        raise RuntimeError(\"No strikes found after processing\")\n",
    "    atm_strike_index = bisect.bisect_left(strikes, underlying_value)\n",
    "    if atm_strike_index > 0 and abs(strikes[atm_strike_index-1] - underlying_value) < abs(strikes[atm_strike_index] - underlying_value):\n",
    "        atm_strike_index -= 1\n",
    "    low_index = max(0, atm_strike_index - num_strikes)\n",
    "    high_index = min(len(strikes) - 1, atm_strike_index + num_strikes)\n",
    "    selected_strikes = strikes[low_index:high_index+1]\n",
    "    df_final = df_processed[df_processed['strikePrice'].isin(selected_strikes)].sort_values(['strikePrice']).reset_index(drop=True)\n",
    "    timestamp = datetime.now().strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "    safe_expiry = str(expiry).replace(' ', '_').replace('/', '-')\n",
    "    base_filename = f\"{index_name.lower()}_option_chain_{safe_expiry}_{timestamp}\"\n",
    "    csv_path = os.path.join(OUTPUT_DIR, f\"{base_filename}.csv\")\n",
    "    meta_path = os.path.join(OUTPUT_DIR, f\"{base_filename}.json\")\n",
    "    # atomic write\n",
    "    _atomic_write_csv(df_final, csv_path)\n",
    "    metadata = {\n",
    "        'createdAtUTC': datetime.utcnow().isoformat(),\n",
    "        'indexName': index_name,\n",
    "        'nearestExpiry': expiry,\n",
    "        'underlyingValue': float(underlying_value),\n",
    "        'atmStrike': int(strikes[atm_strike_index]) if 0 <= atm_strike_index < len(strikes) else None,\n",
    "        'selectedStrikesRange': [int(selected_strikes[0]), int(selected_strikes[-1])],\n",
    "        'totalStrikesFetched': int(len(df_final))\n",
    "    }\n",
    "    _atomic_write_json(metadata, meta_path)\n",
    "    return FetchResultMeta(**metadata)\n",
    "\n",
    "def fetch_and_save_option_chain(index_name: str, num_strikes_around_atm: int = 25) -> FetchResultMeta:\n",
    "    start_time = time.time()\n",
    "    resp = option_chain(index_name)\n",
    "    # find nearest expiry\n",
    "    expiries = resp['records'].get('expiryDates', [])\n",
    "    if not expiries:\n",
    "        raise RuntimeError(\"No expiries in NSE response.\")\n",
    "    nearest_expiry = expiries[0]\n",
    "    df_processed = _prepare_option_chain_df(resp, nearest_expiry)\n",
    "    meta = _select_strikes_and_save(df_processed, resp, index_name, nearest_expiry, num_strikes_around_atm)\n",
    "    elapsed = time.time() - start_time\n",
    "    app.logger.info(f\"Saved option chain for {index_name} expiry {nearest_expiry} in {elapsed:.2f}s\")\n",
    "    return meta\n",
    "\n",
    "def fetch_specific_expiry_option_chain(index_name: str, expiry_date: str, num_strikes_around_atm: int = 25) -> FetchResultMeta:\n",
    "    start_time = time.time()\n",
    "    resp = option_chain(index_name)\n",
    "    expiries = resp['records'].get('expiryDates', [])\n",
    "    if expiry_date not in expiries:\n",
    "        raise HTTPException(status_code=422, detail=f\"Expiry '{expiry_date}' not available. Available: {expiries}\")\n",
    "    df_processed = _prepare_option_chain_df(resp, expiry_date)\n",
    "    meta = _select_strikes_and_save(df_processed, resp, index_name, expiry_date, num_strikes_around_atm)\n",
    "    elapsed = time.time() - start_time\n",
    "    app.logger.info(f\"Saved option chain for {index_name} expiry {expiry_date} in {elapsed:.2f}s\")\n",
    "    return meta\n",
    "\n",
    "# ---------------------------\n",
    "# Provider small wrappers\n",
    "# ---------------------------\n",
    "\n",
    "def get_available_expiries(index_name: str) -> List[str]:\n",
    "    try:\n",
    "        resp = option_chain(index_name)\n",
    "        return resp['records'].get('expiryDates', [])\n",
    "    except Exception as e:\n",
    "        app.logger.error(\"get_available_expiries error: %s\", e)\n",
    "        return []\n",
    "\n",
    "def fetch_index_price(index_name: str) -> dict:\n",
    "    try:\n",
    "        quote = nse_quote(index_name)\n",
    "        if not quote or 'lastPrice' not in quote:\n",
    "            raise HTTPException(status_code=404, detail=f\"No data for index {index_name}\")\n",
    "        last_price = float(str(quote['lastPrice']).replace(',', ''))\n",
    "        return {\n",
    "            'symbol': index_name,\n",
    "            'lastPrice': last_price,\n",
    "            'pChange': float(quote.get('pChange', 0)),\n",
    "            'change': float(quote.get('change', 0)),\n",
    "            'timestamp': quote.get('secDate', datetime.now().strftime(\"%d %b %Y %H:%M:%S\"))\n",
    "        }\n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        app.logger.exception(\"fetch_index_price error\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "def fetch_stock_price(stock_symbol: str) -> dict:\n",
    "    try:\n",
    "        quote = nse_quote(stock_symbol)\n",
    "        info = quote.get('info', {})\n",
    "        price_info = quote.get('priceInfo', {})\n",
    "        if not info or not price_info:\n",
    "            raise HTTPException(status_code=404, detail=f\"No data for stock {stock_symbol}\")\n",
    "        last_price = price_info.get('lastPrice')\n",
    "        try:\n",
    "            last_price = float(last_price) if last_price is not None else None\n",
    "        except Exception:\n",
    "            last_price = None\n",
    "        return {\n",
    "            'symbol': info.get('symbol'),\n",
    "            'companyName': info.get('companyName'),\n",
    "            'lastPrice': last_price,\n",
    "            'pChange': float(price_info.get('pChange', 0)) if price_info.get('pChange') is not None else None,\n",
    "            'change': float(price_info.get('change', 0)) if price_info.get('change') is not None else None,\n",
    "            'timestamp': quote.get('metadata', {}).get('lastUpdateTime', datetime.now().strftime(\"%d-%b-%Y %H:%M:%S\"))\n",
    "        }\n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        app.logger.exception(\"fetch_stock_price error\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "# ---------------------------\n",
    "# REST endpoints\n",
    "# ---------------------------\n",
    "\n",
    "@app.get(\"/expiries\", response_model=List[str])\n",
    "def api_get_expiries(index: str = Query(..., description=\"Index symbol, e.g. NIFTY\")):\n",
    "    idx = _normalize_index_name(index)\n",
    "    expiries = get_available_expiries(idx)\n",
    "    if not expiries:\n",
    "        raise HTTPException(status_code=404, detail=f\"No expiries found for {idx}\")\n",
    "    return expiries\n",
    "\n",
    "@app.get(\"/index-price\", response_model=IndexPriceResponse)\n",
    "def api_index_price(index: str = Query(..., description=\"Index symbol, e.g. NIFTY\")):\n",
    "    idx = _normalize_index_name(index)\n",
    "    data = fetch_index_price(idx)\n",
    "    return IndexPriceResponse(**data)\n",
    "\n",
    "@app.get(\"/stock-price\", response_model=StockPriceResponse)\n",
    "def api_stock_price(symbol: str = Query(..., description=\"Stock symbol (NSE), e.g. RELIANCE\")):\n",
    "    data = fetch_stock_price(symbol.upper())\n",
    "    return StockPriceResponse(**data)\n",
    "\n",
    "@app.post(\"/fetch\", response_model=FetchResultMeta, status_code=201)\n",
    "def api_fetch_options(request: FetchOptionsRequest, background_tasks: BackgroundTasks):\n",
    "    idx = _normalize_index_name(request.index)\n",
    "    # we will fetch in background and return immediately: to keep simple, perform sync fetch\n",
    "    try:\n",
    "        meta = fetch_and_save_option_chain(idx, request.num_strikes)\n",
    "        return meta\n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        app.logger.exception(\"api_fetch_options error\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.post(\"/fetch/expiry\", response_model=FetchResultMeta, status_code=201)\n",
    "def api_fetch_options_expiry(req: FetchExpiryRequest):\n",
    "    idx = _normalize_index_name(req.index)\n",
    "    try:\n",
    "        meta = fetch_specific_expiry_option_chain(idx, req.expiry, req.num_strikes)\n",
    "        return meta\n",
    "    except HTTPException:\n",
    "        raise\n",
    "    except Exception as e:\n",
    "        app.logger.exception(\"api_fetch_options_expiry error\")\n",
    "        raise HTTPException(status_code=500, detail=str(e))\n",
    "\n",
    "@app.get(\"/analytics\", response_model=AnalyticsResponse)\n",
    "def api_analytics_for_latest(index: str = Query(...), limit: int = Query(500, gt=0, le=5000)):\n",
    "    \"\"\"\n",
    "    Read the latest saved CSV for the index and compute analytics.\n",
    "    \"\"\"\n",
    "    idx = _normalize_index_name(index)\n",
    "    files = [f for f in os.listdir(OUTPUT_DIR) if f.startswith(f\"{idx.lower()}_\") and f.endswith('.csv')]\n",
    "    if not files:\n",
    "        raise HTTPException(status_code=404, detail=f\"No saved option-chain CSVs found for {idx}\")\n",
    "    latest_file = sorted(files, reverse=True)[0]\n",
    "    csv_path = os.path.join(OUTPUT_DIR, latest_file)\n",
    "    try:\n",
    "        df = pd.read_csv(csv_path)\n",
    "    except Exception as e:\n",
    "        app.logger.exception(\"Failed to read CSV for analytics\")\n",
    "        raise HTTPException(status_code=500, detail=\"Failed to read saved CSV\")\n",
    "    # apply limit\n",
    "    if limit:\n",
    "        df = df.head(limit)\n",
    "    pcr = calculate_pcr(df)\n",
    "    top_oi = find_high_oi_strikes(df, top_n=5)\n",
    "    max_pain = calculate_max_pain(df)\n",
    "    # load metadata JSON if present\n",
    "    meta_file = csv_path.replace('.csv', '.json')\n",
    "    meta_obj = {}\n",
    "    if os.path.exists(meta_file):\n",
    "        with open(meta_file, 'r', encoding='utf-8') as f:\n",
    "            meta_obj = json.load(f)\n",
    "    meta_obj.setdefault('createdAtUTC', datetime.utcnow().isoformat())\n",
    "    meta = FetchResultMeta(**meta_obj)\n",
    "    return AnalyticsResponse(meta=meta, pcr=pcr, top_oi=top_oi, max_pain=max_pain)\n",
    "\n",
    "# ---------------------------\n",
    "# Simple health endpoint\n",
    "# ---------------------------\n",
    "\n",
    "@app.get(\"/health\")\n",
    "def health():\n",
    "    return {\"status\": \"ok\", \"time\": datetime.utcnow().isoformat()}\n",
    "\n",
    "# ---------------------------\n",
    "# Run example if run directly\n",
    "# ---------------------------\n",
    "if __name__ == \"__main__\":\n",
    "    import uvicorn\n",
    "    uvicorn.run(\"app.main:app\", host=\"127.0.0.1\", port=8000, reload=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03124db4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
